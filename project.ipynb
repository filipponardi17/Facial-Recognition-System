{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, resnet18, squeezenet1_1\n",
    "from torchvision.models.resnet import ResNet50_Weights, ResNet18_Weights\n",
    "from torchvision.models import efficientnet_v2_l\n",
    "from torchvision.models.efficientnet import EfficientNet_V2_L_Weights\n",
    "from torchvision.models import vgg16, vgg19\n",
    "from torchvision.models.vgg import VGG16_Weights, VGG19_Weights\n",
    "from torchvision.models.squeezenet import SqueezeNet1_1_Weights\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tools"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Vgg_face_dag(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Vgg_face_dag, self).__init__()\n",
    "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
    "                     'std': [1, 1, 1],\n",
    "                     'imageSize': [224, 224, 3]}\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc8 = nn.Linear(in_features=4096, out_features=2622, bias=True)\n",
    "\n",
    "    def forward(self, x0):\n",
    "        x1 = self.conv1_1(x0)\n",
    "        x2 = self.relu1_1(x1)\n",
    "        x3 = self.conv1_2(x2)\n",
    "        x4 = self.relu1_2(x3)\n",
    "        x5 = self.pool1(x4)\n",
    "        x6 = self.conv2_1(x5)\n",
    "        x7 = self.relu2_1(x6)\n",
    "        x8 = self.conv2_2(x7)\n",
    "        x9 = self.relu2_2(x8)\n",
    "        x10 = self.pool2(x9)\n",
    "        x11 = self.conv3_1(x10)\n",
    "        x12 = self.relu3_1(x11)\n",
    "        x13 = self.conv3_2(x12)\n",
    "        x14 = self.relu3_2(x13)\n",
    "        x15 = self.conv3_3(x14)\n",
    "        x16 = self.relu3_3(x15)\n",
    "        x17 = self.pool3(x16)\n",
    "        x18 = self.conv4_1(x17)\n",
    "        x19 = self.relu4_1(x18)\n",
    "        x20 = self.conv4_2(x19)\n",
    "        x21 = self.relu4_2(x20)\n",
    "        x22 = self.conv4_3(x21)\n",
    "        x23 = self.relu4_3(x22)\n",
    "        x24 = self.pool4(x23)\n",
    "        x25 = self.conv5_1(x24)\n",
    "        x26 = self.relu5_1(x25)\n",
    "        x27 = self.conv5_2(x26)\n",
    "        x28 = self.relu5_2(x27)\n",
    "        x29 = self.conv5_3(x28)\n",
    "        x30 = self.relu5_3(x29)\n",
    "        x31_preflatten = self.pool5(x30)\n",
    "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
    "        x32 = self.fc6(x31)\n",
    "        x33 = self.relu6(x32)\n",
    "        x34 = self.dropout6(x33)\n",
    "        x35 = self.fc7(x34)\n",
    "        x36 = self.relu7(x35)\n",
    "        x37 = self.dropout7(x36)\n",
    "        x38 = self.fc8(x37)\n",
    "        return x38\n",
    "\n",
    "def vgg_face_dag(weights_path='/home/disi/Project-IML/vgg_face_dag.pth'):\n",
    "\n",
    "    model = Vgg_face_dag()\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "model = vgg_face_dag()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LaBocciaModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LaBocciaModel, self).__init__()\n",
    "        #self.pretrained = squeezenet1_1(weights = SqueezeNet1_1_Weights.DEFAULT)\n",
    "        #self.pretrained = resnet50(weights = ResNet50_Weights.DEFAULT).eval()\n",
    "        #self.pretrained = vgg16(weights = VGG16_Weights.DEFAULT).eval()\n",
    "        #self.pretrained = vgg19(weights = VGG19_Weights.DEFAULT).eval()\n",
    "        #self.pretrained = resnet18(weights = ResNet18_Weights.DEFAULT).eval()\n",
    "        self.pretrained = efficientnet_v2_l(weights = EfficientNet_V2_L_Weights.DEFAULT).eval()\n",
    "        self.pretrained.fc = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        return x\n",
    "\n",
    "model = LaBocciaModel()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from facenet_pytorch import InceptionResnetV1\n",
    "\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Face alignment\n",
    "\n",
    "input_dir = \"/home/disi/Project-IML/query/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "\n",
    "tools.face_alignment(input_dir, output_dir)\n",
    "\n",
    "input_dir = \"/home/disi/Project-IML/gallery/\"\n",
    "output_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "\n",
    "tools.face_alignment(input_dir, output_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# embeddings\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_gallery/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gallery_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "embeddings = tools.embeddings_calc(gallery_paths, model, device, data_dir)\n",
    "\n",
    "\n",
    "data_dir = \"/home/disi/Project-IML/aligned_query/\"\n",
    "\n",
    "query_paths = glob.glob(f\"{data_dir}*\", recursive=True)\n",
    "\n",
    "queries = tools.embeddings_calc(query_paths, model, device, data_dir)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save json\n",
    "def extract_id_competition(comp_id):\n",
    "    splitter = comp_id.split('/')\n",
    "    splitter = splitter[-1]\n",
    "\n",
    "    return splitter\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "query_num_list_10 = []\n",
    "query_num_3 = []\n",
    "query_num_1 = []\n",
    "response_dict = {}\n",
    "results = {}\n",
    "\n",
    "for query in queries:\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = cosine_similarity(query_embedding, gallery_embedding)[0][0]\n",
    "\n",
    "\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "    sorted_distances_10 = sorted_distances[:10]\n",
    "    sorted_distances_3 = sorted_distances[:3]\n",
    "    sorted_distances_1 = sorted_distances[:1]\n",
    "\n",
    "    results[extract_id_competition(query)] = sorted_distances_10\n",
    "\n",
    "    for i, x in enumerate(sorted_distances_10):\n",
    "        sorted_distances_10[i] = extract_id_competition(x[0])\n",
    "\n",
    "\n",
    "response_dict[\"images\"] = results\n",
    "\n",
    "response_dict['groupname'] = 'La Boccia'\n",
    "\n",
    "print(response_dict)\n",
    "\n",
    "import json\n",
    "with open(\"/home/disi/Project-IML/vgg16.json\", \"w\") as write_file:\n",
    "    json.dump(response_dict, write_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#save images\n",
    "\n",
    "def extract_id(string):\n",
    "    splitter = string.split('/')\n",
    "    splitter = splitter[-1].split('.')\n",
    "    splitter = splitter[0]\n",
    "\n",
    "    return splitter\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# iterate over the queries\n",
    "# set the number of retrieved images to display\n",
    "num_retrievals = 5\n",
    "\n",
    "# iterate over the queries\n",
    "for query in queries:\n",
    "    # get the query embedding and calculate distances\n",
    "    query_embedding = queries[query]\n",
    "    distances = {}\n",
    "    for gallery in embeddings:\n",
    "        gallery_embedding = embeddings[gallery]\n",
    "        distances[gallery] = cosine_similarity(query_embedding, gallery_embedding)[0][0]\n",
    "\n",
    "    # sort the distances in descending order\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # get the top retrieved image paths and distances\n",
    "    top_paths = [x[0] for x in sorted_distances[:num_retrievals]]\n",
    "    top_similarities = [x[1]*100 for x in sorted_distances[:num_retrievals]]\n",
    "\n",
    "    # load the query image and the top retrieved images\n",
    "    images = [Image.open(query)] + [Image.open(path) for path in top_paths]\n",
    "\n",
    "    # create a figure with subplots for each image\n",
    "    fig, axes = plt.subplots(1, num_retrievals+1, figsize=(15, 5))\n",
    "\n",
    "    # display the query image\n",
    "    axes[0].imshow(np.array(images[0]))\n",
    "    axes[0].set_title(\"Query\")\n",
    "\n",
    "    # display the retrieved images and their distances\n",
    "    for i in range(num_retrievals):\n",
    "        axes[i+1].imshow(np.array(images[i+1]))\n",
    "        axes[i+1].set_title(f\"Similarity: {top_similarities[i]:.2f}%\")\n",
    "    #plt.show()\n",
    "    plt.savefig(f'/home/disi/Project-IML/EfficientImg/{extract_id(query)}.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
